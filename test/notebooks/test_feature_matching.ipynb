{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01757494-59c0-4d23-9e86-c573f1456686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature Matching\n",
    "\n",
    "This notebook evaluates feature matching performance for a number of test scenarios.\n",
    "\n",
    "TODO: There are images that clearly have bad homographies, but are added together nevertheless.\n",
    "\n",
    "TODO: Refactor the code in here to use the code that the mosaics use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c49e2-2d49-4b74-9c17-1db353507044",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51949404-7b33-4e69-8cb5-acb7823ed70d",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2439067-da17-46ea-b352-7c486a6e2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c22acd-8dff-4b33-a519-0b1bafd4c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.utils import check_random_state\n",
    "import tqdm.notebook\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba2ddf-e6da-4b90-8258-0285e13db00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac252-2f92-4b51-9b68-835fcc917263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from night_horizons import utils, raster, features, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51309b6c-5a10-412c-8185-3a4401d46c65",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb7f2-ef43-4560-bf23-b5f21e68db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yml', \"r\", encoding='UTF-8') as file:\n",
    "    settings = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca608e00-e559-4047-83ed-f90c6be339fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_settings = {\n",
    "    # Filetree settings\n",
    "    'test_images_dir': '../test_data/feature_matching/',\n",
    "    'src_format': 'src_{:03d}.tiff',\n",
    "    'dst_format': 'dst_{:03d}.tiff',\n",
    "    \n",
    "    # What image transformers to test\n",
    "    'img_transformer_names': [\n",
    "        'PassImageTransformer',\n",
    "        'CleanImageTransformer',\n",
    "        'LogscaleImageTransformer',\n",
    "        'CLEAN_LOGSCALE_IMAGE_PIPELINE',\n",
    "    ],\n",
    "\n",
    "    # Feature matching options\n",
    "    'feature_detectors': [\n",
    "        ('ORB', {}),\n",
    "        ('SIFT', {}),\n",
    "        # Still marked as patented in the opencv version I'm using.\n",
    "        # (cv2.xfeatures2d.SURF_create, {}),\n",
    "        ('AKAZE', {}),\n",
    "        # Brisk \"works\" for almost all cases, but many of them are wrong\n",
    "        # ('BRISK', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('FastFeatureDetector', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('MSER', {}),\n",
    "        # ('SimpleBlobDetector', {}),\n",
    "    ],\n",
    "    'feature_matchers': [\n",
    "        # TODO: Explore other feature matchers.\n",
    "        ('BFMatcher', {}),\n",
    "        # ('FlannBasedMatcher', {}),\n",
    "        # ('BFMatcher', {'k': [10,]}),\n",
    "        # TODO: Try Grid-based Motion Statistics. Very fast, but more complicated.\n",
    "    ],\n",
    "    'image_transformers': [\n",
    "        ('PassImageTransformer', {}),\n",
    "        ('CLEAN_LOGSCALE_IMAGE_PIPELINE', {}),\n",
    "    ],\n",
    "    'other_opts_param_grid': {\n",
    "        'homography_method': [\n",
    "            cv2.RANSAC,\n",
    "            # cv2.RHO,\n",
    "            # These don't really show promise\n",
    "            # cv2.LMEDS,\n",
    "            # 0,\n",
    "        ],\n",
    "        # 'ransacReprojThreshold': np.arange(1, 10),\n",
    "        # 'maxIters': [100, 1000, 2000, 10000],\n",
    "        'n_matches_used': [10, 100, 500, None, ],\n",
    "        'required_brightness': [0.01, ],\n",
    "        'required_bright_pixel_area': [50000, ],\n",
    "        # 'det_min': [0.4, ],\n",
    "    },\n",
    "\n",
    "    # Analysis parameters\n",
    "    'det_min': 0.6,\n",
    "    'det_max': 2.0,\n",
    "    'n_images': 10000,\n",
    "    'show_images': True,\n",
    "}\n",
    "settings.update(local_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bfdfb-b036-45cb-ab2b-3a40f7669c1d",
   "metadata": {},
   "source": [
    "## Parse Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cacdff-8d09-4fda-9c71-33423e87ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature detectors\n",
    "feature_detectors = []\n",
    "for subsettings in settings['feature_detectors']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_detectors.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_detectors += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507e051-85b3-4460-8267-ebfa8d842769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature matchers\n",
    "feature_matchers = []\n",
    "for subsettings in settings['feature_matchers']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_matchers.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_matchers += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the image transformers\n",
    "image_transformers = []\n",
    "for subsettings in settings['image_transformers']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        image_transformers.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    image_transformers += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb013f15-4a00-43de-9c44-4c409d689319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get other options\n",
    "\n",
    "# Generate all permutations of values\n",
    "param_grid = settings['other_opts_param_grid']\n",
    "keys, values = zip(*param_grid.items())\n",
    "permutations = itertools.product(*values)\n",
    "\n",
    "other_joiner_options = [\n",
    "    dict(zip(keys, permutation))\n",
    "    for permutation in permutations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74e095-69d5-4d1c-8f65-704e7fe3eda1",
   "metadata": {},
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c71755-ab15-46ea-83e3-f0d5e32dec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinSearcher:\n",
    "\n",
    "    def __init__(self, src_fp, dst_fp):\n",
    "\n",
    "        self.src_fp = src_fp\n",
    "        self.src_image = raster.Image.open(src_fp)\n",
    "        self.src_img = self.src_image.img_int\n",
    "        self.dst_fp = dst_fp\n",
    "        self.dst_image = raster.Image.open(dst_fp)\n",
    "        self.dst_img = self.dst_image.img_int\n",
    "\n",
    "    def show_before(self, img='semitransparent_img', img_transformer=None):\n",
    "\n",
    "        subplot_mosaic = [['dst_img', 'src_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['dst_img']\n",
    "        self.dst_image.show(ax=ax, img=img, img_transformer=img_transformer)\n",
    "        ax.set_title('dst')\n",
    "        \n",
    "        ax = ax_dict['src_img']\n",
    "        self.src_image.show(ax=ax, img=img, img_transformer=img_transformer)\n",
    "        ax.set_title('src')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_after(self, img='semitransparent_img', img_transformer=None):\n",
    "        \n",
    "        # View results\n",
    "        subplot_mosaic = [['warped_img', 'blended_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['warped_img']\n",
    "        self.warped_image.show(ax=ax, img=img, img_transformer=img_transformer)\n",
    "        ax.set_title('warped')\n",
    "        \n",
    "        ax = ax_dict['blended_img']\n",
    "        self.blended_image.show(ax=ax, img=img, img_transformer=img_transformer)\n",
    "        ax.set_title('blended')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def warp_and_blend(self, M):\n",
    "       \n",
    "        # Warp image\n",
    "        self.warped_img = features.ImageJoiner.warp(self.src_img, self.dst_img, M)\n",
    "        self.warped_image = raster.Image(self.warped_img)\n",
    "\n",
    "        # Blend images\n",
    "        self.blended_img = features.ImageJoiner.blend(self.warped_img, self.dst_img)\n",
    "        self.blended_image = raster.Image(self.blended_img)\n",
    "\n",
    "    def grid_search(self, feature_detectors, feature_matchers, other_joiner_options, log_keys=['abs_det_M', 'bright_area']):\n",
    "\n",
    "        n_fd = len(feature_detectors)\n",
    "        n_fm = len(feature_matchers)\n",
    "        n_t = len(image_transformers)\n",
    "        n_oo = len(other_joiner_options)\n",
    "        n_tot = n_fd * n_fm * n_t * n_oo\n",
    "\n",
    "        rows = []\n",
    "        # TODO: Somehow the number of iterations doesn't match with pbar\n",
    "        with tqdm.notebook.tqdm(total=n_tot) as pbar:\n",
    "            for i, fd_settings in enumerate(feature_detectors):\n",
    "                for j, fm_settings in enumerate(feature_matchers):\n",
    "                    for k, t_settings in enumerate(image_transformers):\n",
    "                        for m, other_opts in enumerate(other_joiner_options):\n",
    "    \n",
    "                            image_joiner = features.ImageJoiner(\n",
    "                                feature_detector=fd_settings[0],\n",
    "                                feature_detector_options=fd_settings[1],\n",
    "                                feature_matcher=fm_settings[0],\n",
    "                                feature_matcher_options=fm_settings[1],\n",
    "                                image_transformer=t_settings[0],\n",
    "                                image_transformer_options=t_settings[1],\n",
    "                                log_keys=log_keys,\n",
    "                                **other_opts\n",
    "                            )\n",
    "        \n",
    "                            return_code, results_ijkm, log = image_joiner.join(\n",
    "                                self.src_img, self.dst_img)\n",
    "        \n",
    "                            # Store results\n",
    "                            row = {\n",
    "                                'return_code': return_code,\n",
    "                                'i_fd': i,\n",
    "                                'j_fm': j,\n",
    "                                'k_t': k,\n",
    "                                'm_oo': m,\n",
    "                            }\n",
    "                            # Make blanks for things we want to log no matter what\n",
    "                            row_defaults = {key: np.nan for key in log_keys}\n",
    "                            row.update(row_defaults)\n",
    "                            # Actual update\n",
    "                            row.update(results_ijkm)\n",
    "                            row.update(log)\n",
    "                            rows.append(row)\n",
    "\n",
    "                            pbar.update(1)\n",
    "                        pbar.update(1)\n",
    "                    pbar.update(1)\n",
    "                pbar.update(1)\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Measure of how warped the image is\n",
    "        df['warp_factor'] = np.abs(np.log10(np.abs(df['abs_det_M'])))\n",
    "\n",
    "        # Identify the best set of parameters\n",
    "        df['valid_M'] = df['return_code'] == 'success'\n",
    "        valid_df = df.loc[df['valid_M']]\n",
    "        if len(valid_df) > 0:\n",
    "            best_ind = valid_df.index[valid_df['duration'].argmin()]\n",
    "        else:\n",
    "            best_ind = df.index[df['warp_factor'].argmin()]\n",
    "        best_row = df.loc[best_ind]\n",
    "        t_best_ind = pd.Timedelta(\n",
    "            settings['n_images'] * best_row['duration'], unit='second')\n",
    "\n",
    "        # Results\n",
    "        gs_info = {\n",
    "            'n_valid': len(valid_df),\n",
    "            'best_ind': best_ind,\n",
    "            't_best_ind': t_best_ind,\n",
    "            'best_fd': feature_detectors[best_row['i_fd']],\n",
    "            'best_fm': feature_matchers[best_row['j_fm']],\n",
    "            'best_t': image_transformers[best_row['k_t']],\n",
    "            'best_oo': other_joiner_options[best_row['m_oo']],\n",
    "        }\n",
    "\n",
    "        if len(valid_df) > 0:\n",
    "            print(\n",
    "                f'''Grid search complete.\n",
    "                    {gs_info['n_valid']} valid results.\n",
    "                    Best valid time was {best_row['duration']:.2g} seconds, for an estimated total time of {gs_info['t_best_ind']}.\n",
    "                    The best feature detector was {gs_info['best_fd']}\n",
    "                    The best feature matcher was {gs_info['best_fm']}\n",
    "                    The best transformer was {gs_info['best_t']}\n",
    "                    The best other options were {gs_info['best_oo']}\n",
    "                '''\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f'''No successes found. Closest det_min was {best_row['abs_det_M']:.3g}\n",
    "                '''\n",
    "            )\n",
    "\n",
    "        self.df = df\n",
    "        self.best_row = best_row\n",
    "        self.gs_info = gs_info\n",
    "\n",
    "        return df, best_row, gs_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe75c4-d7a5-48d7-95af-d189ae222c11",
   "metadata": {},
   "source": [
    "# Test Image Joins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d8d70-8077-4319-acab-87b90ea527ca",
   "metadata": {},
   "source": [
    "## A Particular Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ce8a8-0e77-42a9-97f1-7d5ddd9f7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "js = JoinSearcher(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0c94f-d7f7-40fc-be17-d75d20e11ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    js.show_before(\n",
    "        img='img_int',\n",
    "        img_transformer=preprocess.CLEAN_LOGSCALE_IMAGE_PIPELINE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7debc-b3cc-4eef-a598-3a212c62fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = js.grid_search(feature_detectors, feature_matchers, other_joiner_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3b8a9-6a8e-414a-8c56-d319342cf2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = best_row\n",
    "row = df.loc[8]\n",
    "if 'M' in row:\n",
    "    js.warp_and_blend(row['M'])\n",
    "\n",
    "    t_settings = image_transformers[row['k_t']]\n",
    "    img_transformer = getattr(preprocess, t_settings[0])(**t_settings[1])\n",
    "\n",
    "    if settings['show_images']:\n",
    "        js.show_after(\n",
    "            img='img_int',\n",
    "            img_transformer=img_transformer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca74c64-1cea-4c6a-b6b3-449c4f0c21fb",
   "metadata": {},
   "source": [
    "## All Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22722122-dab8-4827-8d23-bf0861f679a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fps = sorted(glob.glob(os.path.join(settings['test_images_dir'], 'src_*.tiff')))\n",
    "dst_fps = sorted(glob.glob(os.path.join(settings['test_images_dir'], 'dst_*.tiff')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351e008-10fd-475f-8366-1b6c4ebb0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, src_fp in enumerate(src_fps):\n",
    "    print(f'i = {i} / {len(src_fps)}')\n",
    "    \n",
    "    dst_fp = dst_fps[i]\n",
    "\n",
    "    fc = JoinSearcher(src_fp, dst_fp)\n",
    "    \n",
    "    df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers, other_joiner_options)\n",
    "    \n",
    "    df['set'] = i\n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be81117-1ea5-4e29-952f-998b63218630",
   "metadata": {},
   "source": [
    "## Summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaea261-169b-4b33-a75f-788a57a00ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c53f25-2595-471e-a4ec-ed0d0b5aba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ijkm'] = 'i' + df['i_fd'].astype(str) + '_j' + df['j_fm'].astype(str) + '_k' + df['k_t'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0a9b5-ac11-485e-8e44-55786f36066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df.loc[df['valid_M']]\n",
    "valid_or_dark_df = df.loc[df['return_code'].isin(['success', 'dark_frame'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5129c7a-7e58-4bf5-88d0-9363482d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sets = pd.unique(df['set']).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266b152-e0a9-4979-9dfa-14e91ee87d1d",
   "metadata": {},
   "source": [
    "### Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c788e2-dac1-4e1a-85b9-f127c4d5a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='duration',\n",
    "    y='warp_factor',\n",
    "    hue='valid_M',\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axhline(np.abs(np.log10(settings['det_min'])))\n",
    "ax.set_ylim(0, ax.get_ylim()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb01bc-d90b-41c8-9095-de66aa3f898e",
   "metadata": {},
   "source": [
    "### Identify Promising Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cf218-22f5-41df-bb3b-4b7ad87f5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature detectors that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('i_fd')['set'].nunique()\n",
    "promising_i_fd = n_valid_sets.index[n_valid_sets==n_sets]\n",
    "promising_fd = [feature_detectors[_] for _ in promising_i_fd]\n",
    "promising_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749e1b8-b83d-448f-a553-daf9402634a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matchers that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('j_fm')['set'].nunique()\n",
    "promising_fm = [feature_matchers[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "promising_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matchers that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('k_t')['set'].nunique()\n",
    "promising_t = [image_transformers[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "promising_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a0285-9c8b-49fc-8e00-506b797a0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform parameters that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('k_t')['set'].nunique()\n",
    "promising_t_kwargs = [other_joiner_options[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "method_map = {\n",
    "    getattr(cv2, method): method\n",
    "    for method in ['RANSAC', 'LMEDS', 'RHO']\n",
    "}\n",
    "promising_t_kwargs = [\n",
    "    {\n",
    "        key:(method_map[value] if key == 'method' else value)\n",
    "        for key, value in t_kwargs.items()\n",
    "    } for t_kwargs in promising_t_kwargs\n",
    "]\n",
    "promising_t_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6228cd-8c73-474e-9505-9b121f544984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now the combinations that are fully good\n",
    "ijkm_groups = valid_or_dark_df.groupby('ijkm')\n",
    "n_valid_sets = ijkm_groups['set'].nunique()\n",
    "is_good = n_valid_sets == n_sets\n",
    "good_ijkms = n_valid_sets.index[is_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ab78e-431a-4c1d-bb56-e4c2a75ac31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_good.sum() > 0:\n",
    "    # Convert into a dataframe\n",
    "    good_df = ijkm_groups.first().loc[good_ijkms]\n",
    "    good_df['duration'] = ijkm_groups['duration'].mean().loc[good_ijkms]\n",
    "    good_df = good_df.sort_values('duration')\n",
    "    best_row = good_df.iloc[0]\n",
    "\n",
    "    # Print the best (quickest while still valid) combination\n",
    "    print(\n",
    "        feature_detectors[best_row['i_fd']],\n",
    "        feature_matchers[best_row['j_fm']],\n",
    "        image_transformers[best_row['k_t']],\n",
    "        other_joiner_options[best_row['m_oo']]\n",
    "    )\n",
    "else:\n",
    "    print('No single set of parameters works for all images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "import importlib\n",
    "importlib.reload(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "image = raster.Image.open(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want our transforms to be smooth.\n",
    "class treat_warnings_as_errors:\n",
    "    def __enter__(self):\n",
    "        warnings.simplefilter(\"error\")\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with treat_warnings_as_errors():\n",
    "\n",
    "    transformed_imgs = []\n",
    "    for img_transformer_name in settings['img_transformer_names']:\n",
    "\n",
    "        img_transformer = getattr(preprocess, img_transformer_name)\n",
    "        if callable(img_transformer):\n",
    "            img_transformer = img_transformer()\n",
    "\n",
    "        try:\n",
    "            img_t = img_transformer.fit_transform(X=[image.img_int])[0]\n",
    "        except NotImplementedError:\n",
    "            continue\n",
    "        image_t = raster.Image(img_t)\n",
    "\n",
    "        transformed_imgs.append(image_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    figsize = np.array(image.img_shape) / 240.\n",
    "    ncol = len(settings['img_transformer_names'])\n",
    "    subplot_mosaic = [[_, ] for _ in settings['img_transformer_names']]\n",
    "    figsize[1] *= ncol\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "\n",
    "    for i, image_t in enumerate(transformed_imgs):\n",
    "\n",
    "        img_transformer_name = settings['img_transformer_names'][i]\n",
    "\n",
    "        ax = ax_dict[img_transformer_name]\n",
    "        image_t.show(ax=ax)\n",
    "\n",
    "        ax.set_title(img_transformer_name)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Feature Detection Details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_joiner = features.ImageJoiner(\n",
    "    feature_detector='AKAZE',\n",
    "    feature_detector_options={},\n",
    "    feature_matcher='BFMatcher',\n",
    "    feature_matcher_options={},\n",
    "    image_transformer='CLEAN_LOGSCALE_IMAGE_PIPELINE',\n",
    "    image_transformer_options={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_kp, dst_des = image_joiner.detect_and_compute(js.dst_img)\n",
    "dst_pts = cv2.KeyPoint_convert(dst_kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js.dst_image.show()\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.scatter(\n",
    "    dst_pts[:,0],\n",
    "    dst_pts[:,1],\n",
    "    color='none',\n",
    "    edgecolor='w',\n",
    "    linewidth=3,\n",
    "    s=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "dst_pt = dst_pts[k]\n",
    "dst_de = dst_des[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw = 128\n",
    "px_min = max(int(dst_pt[1] - hw), 0)\n",
    "px_max = min(int(dst_pt[1] + hw), js.dst_img.shape[0])\n",
    "py_min = max(int(dst_pt[0] - hw), 0)\n",
    "py_max = min(int(dst_pt[0] + hw), js.dst_img.shape[1])\n",
    "zoom = js.dst_img[px_min:px_max, py_min:py_max]\n",
    "zoom_image = raster.Image(zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.gca()\n",
    "\n",
    "zoom_image.show(\n",
    "    ax=ax,\n",
    "    img='img_int',\n",
    "    img_transformer=image_joiner.image_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
