{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01757494-59c0-4d23-9e86-c573f1456686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature Matching\n",
    "\n",
    "This notebook evaluates feature matching performance for a number of test scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c49e2-2d49-4b74-9c17-1db353507044",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51949404-7b33-4e69-8cb5-acb7823ed70d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2439067-da17-46ea-b352-7c486a6e2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "import itertools\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c22acd-8dff-4b33-a519-0b1bafd4c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.utils import check_random_state\n",
    "import tqdm.notebook\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba2ddf-e6da-4b90-8258-0285e13db00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac252-2f92-4b51-9b68-835fcc917263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from night_horizons import utils, raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51309b6c-5a10-412c-8185-3a4401d46c65",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb7f2-ef43-4560-bf23-b5f21e68db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yml', \"r\", encoding='UTF-8') as file:\n",
    "    settings = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca608e00-e559-4047-83ed-f90c6be339fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_settings = {\n",
    "    # Filetree settings\n",
    "    'test_images_dir': '../test_data/feature_matching/',\n",
    "    'src_format': 'src_{}.tiff',\n",
    "    'dst_format': 'dst_{}.tiff',\n",
    "\n",
    "    # Feature matching options\n",
    "    'feature_detectors': [\n",
    "        ('ORB', {}),\n",
    "        ('SIFT', {}),\n",
    "        # Still marked as patented in the opencv version I'm using.\n",
    "        # (cv2.xfeatures2d.SURF_create, {}),\n",
    "        ('AKAZE', {}),\n",
    "        ('BRISK', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('FastFeatureDetector', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('MSER', {}),\n",
    "    ],\n",
    "    'feature_matchers': [\n",
    "        # TODO: Explore other feature matchers.\n",
    "        ('BFMatcher', {}),\n",
    "        # ('FlannBasedMatcher', {}),\n",
    "        # ('BFMatcher', {'k': [10,]}),\n",
    "        # TODO: Try Grid-based Motion Statistics. Very fast, but more complicated.\n",
    "    ],\n",
    "    'fm_grid': {},\n",
    "\n",
    "    # Parameters\n",
    "    'det_min': 0.6,\n",
    "    'n_images': 10000,\n",
    "}\n",
    "settings.update(local_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bfdfb-b036-45cb-ab2b-3a40f7669c1d",
   "metadata": {},
   "source": [
    "## Parse Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cacdff-8d09-4fda-9c71-33423e87ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature detectors\n",
    "feature_detectors = []\n",
    "for subsettings in settings['feature_detectors']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_detectors.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_detectors += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507e051-85b3-4460-8267-ebfa8d842769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature matchers\n",
    "feature_matchers = []\n",
    "for subsettings in settings['feature_matchers']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_matchers.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_matchers += list_addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74e095-69d5-4d1c-8f65-704e7fe3eda1",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c71755-ab15-46ea-83e3-f0d5e32dec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureCombiner:\n",
    "\n",
    "    def __init__(self, src_fp, dst_fp):\n",
    "\n",
    "        self.src_fp = src_fp\n",
    "        self.src_image = raster.Image.open(src_fp)\n",
    "        self.src_img = self.src_image.img_int\n",
    "        self.dst_fp = dst_fp\n",
    "        self.dst_image = raster.Image.open(dst_fp)\n",
    "        self.dst_img = self.dst_image.img_int\n",
    "\n",
    "    def show_before(self):\n",
    "\n",
    "        subplot_mosaic = [['dst_img', 'src_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['dst_img']\n",
    "        self.dst_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        ax = ax_dict['src_img']\n",
    "        self.src_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_after(self):\n",
    "        \n",
    "        # View results\n",
    "        subplot_mosaic = [['warped_img', 'blended_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['warped_img']\n",
    "        self.warped_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        ax = ax_dict['blended_img']\n",
    "        self.blended_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def detect_and_transform(self, feature_detector, feature_matcher, pbar=None):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Get keypoints\n",
    "        src_kp, src_des = feature_detector.detectAndCompute(self.src_img, None)\n",
    "        dst_kp, dst_des = feature_detector.detectAndCompute(self.dst_img, None)\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Get transform\n",
    "        M, info = utils.calc_warp_transform(src_kp, src_des, dst_kp, dst_des, feature_matcher)\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "            \n",
    "        # Check transform\n",
    "        valid_M, abs_det_M = utils.validate_warp_transform(M, det_min=settings['det_min'])\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "            \n",
    "        duration = time.time() - start\n",
    "\n",
    "        info['valid_M'] = valid_M\n",
    "        info['abs_det_M'] = abs_det_M\n",
    "        info['duration'] = duration\n",
    "        info['M'] = M\n",
    "\n",
    "        return info\n",
    "\n",
    "    def warp_and_blend(self, M):\n",
    "        \n",
    "        # Warp and blend\n",
    "        warped_img = cv2.warpPerspective(self.src_img, M, (self.dst_img.shape[1], self.dst_img.shape[0]))\n",
    "        self.warped_image = raster.Image(warped_img)\n",
    "        blended_img = utils.blend_images(\n",
    "            src_img=warped_img,\n",
    "            dst_img=self.dst_img,\n",
    "        )\n",
    "        self.blended_image = raster.Image(blended_img[:, :, :3])\n",
    "\n",
    "    def grid_search(self, feature_detectors, feature_matchers):\n",
    "\n",
    " \n",
    "        n_fd = len(feature_detectors)\n",
    "        n_fm = len(feature_matchers)\n",
    "        n_stages = 3\n",
    "\n",
    "        data = {}\n",
    "        with tqdm.notebook.tqdm(total=n_fd * n_fm * n_stages) as pbar:\n",
    "        \n",
    "            for i, fd_settings in enumerate(feature_detectors):\n",
    "\n",
    "                if isinstance(fd_settings[0], str):\n",
    "                    fd_constructor = getattr(cv2, '{}_create'.format(fd_settings[0]))\n",
    "                else:\n",
    "                    fd_constructor = fd_settings[0]\n",
    "        \n",
    "                feature_detector = fd_constructor(**fd_settings[1])\n",
    "                \n",
    "                for j, fm_settings in enumerate(feature_matchers):\n",
    "        \n",
    "                    feature_matcher = getattr(cv2, '{}'.format(fm_settings[0]))(**fm_settings[1])\n",
    "\n",
    "                    result_ij = self.detect_and_transform(feature_detector, feature_matcher, pbar)\n",
    "\n",
    "                    for key, item in result_ij.items():\n",
    "                        data.setdefault(key, []).append(item)\n",
    "        \n",
    "                    data.setdefault('i_fd', []).append(i)\n",
    "                    data.setdefault('j_fm', []).append(j)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Identify the best set of parameters\n",
    "        valid_df = df.loc[df['valid_M']]\n",
    "        best_ind = valid_df.index[valid_df['duration'].argmin()]\n",
    "        best_row = df.loc[best_ind]\n",
    "        t_best_ind = pd.Timedelta(settings['n_images'] * best_row['duration'], unit='second')\n",
    "\n",
    "        # Results\n",
    "        gs_info = {\n",
    "            'n_valid': df['valid_M'].sum(),\n",
    "            'best_ind': best_ind,\n",
    "            't_best_ind': t_best_ind,\n",
    "            'best_fd': feature_detectors[best_row['i_fd']],\n",
    "            'best_fm': feature_matchers[best_row['j_fm']],\n",
    "        }\n",
    "        print(\n",
    "            f'''Grid search complete.\n",
    "                {gs_info['n_valid']} valid results.\n",
    "                Best valid time was {best_row['duration']:.2g} seconds, for an estimated total time of {gs_info['t_best_ind']}.\n",
    "                The best feature detector was {gs_info['best_fd']}\n",
    "                The best feature matcher was {gs_info['best_fm']}\n",
    "            '''\n",
    "        )\n",
    "\n",
    "        self.df = df\n",
    "        self.best_row = best_row\n",
    "        self.gs_info = gs_info\n",
    "\n",
    "        return df, best_row, gs_info   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe75c4-d7a5-48d7-95af-d189ae222c11",
   "metadata": {},
   "source": [
    "# Image Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d8d70-8077-4319-acab-87b90ea527ca",
   "metadata": {},
   "source": [
    "## Set 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ce8a8-0e77-42a9-97f1-7d5ddd9f7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "fc = FeatureCombiner(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0c94f-d7f7-40fc-be17-d75d20e11ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.show_before()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7debc-b3cc-4eef-a598-3a212c62fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3b8a9-6a8e-414a-8c56-d319342cf2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.warp_and_blend(best_row['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23e331-12c4-4ddb-9823-2d169c902824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.show_after()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca74c64-1cea-4c6a-b6b3-449c4f0c21fb",
   "metadata": {},
   "source": [
    "## Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa8fdd-52d5-45b0-b365-c54aef08695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "fc = FeatureCombiner(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe01cb-14d2-4d3d-9038-870bbf96efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.show_before()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee472425-da47-428a-82bc-38d95249e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d27296-a336-43d0-b83e-5f98cccc13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.warp_and_blend(best_row['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58cd72-6065-43d1-8b38-3039c1b5dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.show_after()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
