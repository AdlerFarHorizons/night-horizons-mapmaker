{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01757494-59c0-4d23-9e86-c573f1456686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature Matching\n",
    "\n",
    "This notebook evaluates feature matching performance for a number of test scenarios.\n",
    "\n",
    "TODO: There are images that clearly have bad homographies, but are added together nevertheless.\n",
    "\n",
    "TODO: Refactor the code in here to use the code that the mosaics use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c49e2-2d49-4b74-9c17-1db353507044",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51949404-7b33-4e69-8cb5-acb7823ed70d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2439067-da17-46ea-b352-7c486a6e2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "import itertools\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c22acd-8dff-4b33-a519-0b1bafd4c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.utils import check_random_state\n",
    "import tqdm.notebook\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba2ddf-e6da-4b90-8258-0285e13db00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac252-2f92-4b51-9b68-835fcc917263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from night_horizons import utils, raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51309b6c-5a10-412c-8185-3a4401d46c65",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb7f2-ef43-4560-bf23-b5f21e68db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yml', \"r\", encoding='UTF-8') as file:\n",
    "    settings = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca608e00-e559-4047-83ed-f90c6be339fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_settings = {\n",
    "    # Filetree settings\n",
    "    'test_images_dir': '../test_data/feature_matching/',\n",
    "    'src_format': 'src_{}.tiff',\n",
    "    'dst_format': 'dst_{}.tiff',\n",
    "\n",
    "    # Feature matching options\n",
    "    'feature_detectors': [\n",
    "        ('ORB', {}),\n",
    "        ('SIFT', {}),\n",
    "        # Still marked as patented in the opencv version I'm using.\n",
    "        # (cv2.xfeatures2d.SURF_create, {}),\n",
    "        ('AKAZE', {}),\n",
    "        # ('BRISK', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('FastFeatureDetector', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('MSER', {}),\n",
    "    ],\n",
    "    'feature_matchers': [\n",
    "        # TODO: Explore other feature matchers.\n",
    "        ('BFMatcher', {}),\n",
    "        # ('FlannBasedMatcher', {}),\n",
    "        # ('BFMatcher', {'k': [10,]}),\n",
    "        # TODO: Try Grid-based Motion Statistics. Very fast, but more complicated.\n",
    "    ],\n",
    "    'transform_param_grid': {\n",
    "        'method': [\n",
    "            cv2.RANSAC,\n",
    "            # cv2.RHO,\n",
    "            # These don't really show promise\n",
    "            # cv2.LMEDS,\n",
    "            # 0,\n",
    "        ],\n",
    "        # 'ransacReprojThreshold': np.arange(1, 10),\n",
    "        # 'maxIters': [100, 1000, 2000, 10000],\n",
    "        'n_matches_used': [10, 100, 500, None],\n",
    "    },\n",
    "\n",
    "    # Analysis parameters\n",
    "    'det_min': 0.6,\n",
    "    'n_images': 10000,\n",
    "    'show_images': True,\n",
    "}\n",
    "settings.update(local_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bfdfb-b036-45cb-ab2b-3a40f7669c1d",
   "metadata": {},
   "source": [
    "## Parse Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cacdff-8d09-4fda-9c71-33423e87ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature detectors\n",
    "feature_detectors = []\n",
    "for subsettings in settings['feature_detectors']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_detectors.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_detectors += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507e051-85b3-4460-8267-ebfa8d842769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature matchers\n",
    "feature_matchers = []\n",
    "for subsettings in settings['feature_matchers']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_matchers.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_matchers += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb013f15-4a00-43de-9c44-4c409d689319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transform kwargs\n",
    "\n",
    "# Generate all permutations of values\n",
    "param_grid = settings['transform_param_grid']\n",
    "keys, values = zip(*param_grid.items())\n",
    "permutations = itertools.product(*values)\n",
    "\n",
    "transform_kwargs = [\n",
    "    dict(zip(keys, permutation))\n",
    "    for permutation in permutations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74e095-69d5-4d1c-8f65-704e7fe3eda1",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c71755-ab15-46ea-83e3-f0d5e32dec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureCombiner:\n",
    "\n",
    "    def __init__(self, src_fp, dst_fp):\n",
    "\n",
    "        self.src_fp = src_fp\n",
    "        self.src_image = raster.Image.open(src_fp)\n",
    "        self.src_img = self.src_image.img_int\n",
    "        self.dst_fp = dst_fp\n",
    "        self.dst_image = raster.Image.open(dst_fp)\n",
    "        self.dst_img = self.dst_image.img_int\n",
    "\n",
    "    def show_before(self):\n",
    "\n",
    "        subplot_mosaic = [['dst_img', 'src_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['dst_img']\n",
    "        self.dst_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        ax = ax_dict['src_img']\n",
    "        self.src_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_after(self):\n",
    "        \n",
    "        # View results\n",
    "        subplot_mosaic = [['warped_img', 'blended_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['warped_img']\n",
    "        self.warped_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        ax = ax_dict['blended_img']\n",
    "        self.blended_image.show(ax=ax, img='semitransparent_img')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def detect_and_transform(self, feature_detector, feature_matcher, transform_kwargs, pbar=None):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Get keypoints\n",
    "        src_kp, src_des = feature_detector.detectAndCompute(self.src_img, None)\n",
    "        dst_kp, dst_des = feature_detector.detectAndCompute(self.dst_img, None)\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Get transform\n",
    "        M, info = utils.calc_warp_transform(\n",
    "            src_kp,\n",
    "            src_des,\n",
    "            dst_kp,\n",
    "            dst_des,\n",
    "            feature_matcher,\n",
    "            **transform_kwargs\n",
    "        )\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "            \n",
    "        # Check transform\n",
    "        valid_M, abs_det_M = utils.validate_warp_transform(M, det_min=settings['det_min'])\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "            \n",
    "        duration = time.time() - start\n",
    "\n",
    "        info['valid_M'] = valid_M\n",
    "        info['abs_det_M'] = abs_det_M\n",
    "        info['duration'] = duration\n",
    "        info['M'] = M\n",
    "\n",
    "        return info\n",
    "\n",
    "    def warp_and_blend(self, M):\n",
    "        \n",
    "        # Warp and blend\n",
    "        warped_img = cv2.warpPerspective(self.src_img, M, (self.dst_img.shape[1], self.dst_img.shape[0]))\n",
    "        self.warped_image = raster.Image(warped_img)\n",
    "        blended_img = utils.blend_images(\n",
    "            src_img=warped_img,\n",
    "            dst_img=self.dst_img,\n",
    "        )\n",
    "        self.blended_image = raster.Image(blended_img[:, :, :3])\n",
    "\n",
    "    def grid_search(self, feature_detectors, feature_matchers, transform_kwargs):\n",
    "\n",
    " \n",
    "        n_fd = len(feature_detectors)\n",
    "        n_fm = len(feature_matchers)\n",
    "        n_t = len(transform_kwargs)\n",
    "        n_stages = 3\n",
    "        n_tot = n_fd * n_fm * n_t * n_stages\n",
    "\n",
    "        data = {}\n",
    "        with tqdm.notebook.tqdm(total=n_tot) as pbar:\n",
    "        \n",
    "            for i, fd_settings in enumerate(feature_detectors):\n",
    "\n",
    "                if isinstance(fd_settings[0], str):\n",
    "                    fd_constructor = getattr(cv2, '{}_create'.format(fd_settings[0]))\n",
    "                else:\n",
    "                    fd_constructor = fd_settings[0]\n",
    "        \n",
    "                feature_detector = fd_constructor(**fd_settings[1])\n",
    "                \n",
    "                for j, fm_settings in enumerate(feature_matchers):\n",
    "\n",
    "                    for k, t_kwargs in enumerate(transform_kwargs):\n",
    "        \n",
    "                        feature_matcher = getattr(cv2, '{}'.format(fm_settings[0]))(**fm_settings[1])\n",
    "    \n",
    "                        result_ijk = self.detect_and_transform(feature_detector, feature_matcher, t_kwargs, pbar)\n",
    "    \n",
    "                        for key, item in result_ijk.items():\n",
    "                            data.setdefault(key, []).append(item)\n",
    "            \n",
    "                        data.setdefault('i_fd', []).append(i)\n",
    "                        data.setdefault('j_fm', []).append(j)\n",
    "                        data.setdefault('k_tk', []).append(k)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Measure of how warped the image is\n",
    "        df['warp_factor'] = np.abs(np.log10(np.abs(df['abs_det_M'])))\n",
    "\n",
    "        # Identify the best set of parameters\n",
    "        valid_df = df.loc[df['valid_M']]\n",
    "        if len(valid_df) > 0:\n",
    "            best_ind = valid_df.index[valid_df['duration'].argmin()]\n",
    "        else:\n",
    "            best_ind = df.index[df['warp_factor'].argmin()]\n",
    "        best_row = df.loc[best_ind]\n",
    "        t_best_ind = pd.Timedelta(settings['n_images'] * best_row['duration'], unit='second')\n",
    "\n",
    "        # Results\n",
    "        gs_info = {\n",
    "            'n_valid': len(valid_df),\n",
    "            'best_ind': best_ind,\n",
    "            't_best_ind': t_best_ind,\n",
    "            'best_fd': feature_detectors[best_row['i_fd']],\n",
    "            'best_fm': feature_matchers[best_row['j_fm']],\n",
    "            'best_tk': transform_kwargs[best_row['k_tk']],\n",
    "        }\n",
    "\n",
    "        if len(valid_df) > 0:\n",
    "            print(\n",
    "                f'''Grid search complete.\n",
    "                    {gs_info['n_valid']} valid results.\n",
    "                    Best valid time was {best_row['duration']:.2g} seconds, for an estimated total time of {gs_info['t_best_ind']}.\n",
    "                    The best feature detector was {gs_info['best_fd']}\n",
    "                    The best feature matcher was {gs_info['best_fm']}\n",
    "                    The best transform kwargs were {gs_info['best_tk']}\n",
    "                '''\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f'''No successes found. Closest det_min was \n",
    "                '''\n",
    "            )\n",
    "\n",
    "        self.df = df\n",
    "        self.best_row = best_row\n",
    "        self.gs_info = gs_info\n",
    "\n",
    "        return df, best_row, gs_info   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe75c4-d7a5-48d7-95af-d189ae222c11",
   "metadata": {},
   "source": [
    "# Image Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe746c-b3a2-4735-90bc-e3fb75eda65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d8d70-8077-4319-acab-87b90ea527ca",
   "metadata": {},
   "source": [
    "## Set 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ce8a8-0e77-42a9-97f1-7d5ddd9f7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "fc = FeatureCombiner(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0c94f-d7f7-40fc-be17-d75d20e11ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    fc.show_before()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7debc-b3cc-4eef-a598-3a212c62fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers, transform_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3b8a9-6a8e-414a-8c56-d319342cf2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.warp_and_blend(best_row['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23e331-12c4-4ddb-9823-2d169c902824",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    fc.show_after()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f617ae3-5604-4e60-9de7-10bfb7fbe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = i\n",
    "results.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca74c64-1cea-4c6a-b6b3-449c4f0c21fb",
   "metadata": {},
   "source": [
    "## Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa8fdd-52d5-45b0-b365-c54aef08695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "fc = FeatureCombiner(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe01cb-14d2-4d3d-9038-870bbf96efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    fc.show_before()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee472425-da47-428a-82bc-38d95249e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers, transform_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d27296-a336-43d0-b83e-5f98cccc13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.warp_and_blend(best_row['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58cd72-6065-43d1-8b38-3039c1b5dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    fc.show_after()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4039fbb-6fea-49fa-bbe4-9c51036e3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = i\n",
    "results.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb0295-b8a0-4536-b975-7fac462b4b4b",
   "metadata": {},
   "source": [
    "## Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447adbd-1cc9-45f7-92cd-a51bb48ead64",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "fc = FeatureCombiner(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b86bf-15a3-4074-a0c8-b86056144340",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    fc.show_before()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad229c5-9845-4976-8d5d-4acfd212d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers, transform_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca8304-c937-455a-91da-5c4e1a1a1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.warp_and_blend(best_row['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94b43e-f619-4ca6-97bb-251e451fd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    fc.show_after()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a0763-086a-42a1-bd23-da3edecbf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = i\n",
    "results.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be81117-1ea5-4e29-952f-998b63218630",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaea261-169b-4b33-a75f-788a57a00ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c53f25-2595-471e-a4ec-ed0d0b5aba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ijk'] = 'i' + df['i_fd'].astype(str) + '_j' + df['j_fm'].astype(str) + '_k' + df['k_tk'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0a9b5-ac11-485e-8e44-55786f36066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df.loc[df['valid_M']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5129c7a-7e58-4bf5-88d0-9363482d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sets = pd.unique(df['set']).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266b152-e0a9-4979-9dfa-14e91ee87d1d",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c788e2-dac1-4e1a-85b9-f127c4d5a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='duration',\n",
    "    y='warp_factor',\n",
    "    hue='valid_M',\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axhline(np.abs(np.log10(settings['det_min'])))\n",
    "ax.set_ylim(0, ax.get_ylim()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb01bc-d90b-41c8-9095-de66aa3f898e",
   "metadata": {},
   "source": [
    "### Identify Promising Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cf218-22f5-41df-bb3b-4b7ad87f5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature detectors that work across all image pairs\n",
    "n_valid_sets = valid_df.groupby('i_fd')['set'].nunique()\n",
    "promising_fd = [feature_detectors[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "promising_fddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749e1b8-b83d-448f-a553-daf9402634a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matchers that work across all image pairs\n",
    "n_valid_sets = valid_df.groupby('j_fm')['set'].nunique()\n",
    "promising_fm = [feature_matchers[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "promising_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a0285-9c8b-49fc-8e00-506b797a0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform parameters that work across all image pairs\n",
    "n_valid_sets = valid_df.groupby('k_tk')['set'].nunique()\n",
    "promising_t_kwargs = [transform_kwargs[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "method_map = {\n",
    "    getattr(cv2, method): method\n",
    "    for method in ['RANSAC', 'LMEDS', 'RHO']\n",
    "}\n",
    "promising_t_kwargs = [\n",
    "    {\n",
    "        key:(method_map[value] if key == 'method' else value)\n",
    "        for key, value in t_kwargs.items()\n",
    "    } for t_kwargs in promising_t_kwargs\n",
    "]\n",
    "promising_t_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6228cd-8c73-474e-9505-9b121f544984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now the combinations that are fully good\n",
    "ijk_groups = valid_df.groupby('ijk')\n",
    "n_valid_sets = ijk_groups['set'].nunique()\n",
    "is_good = n_valid_sets == n_sets\n",
    "good_ijks = n_valid_sets.index[is_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ab78e-431a-4c1d-bb56-e4c2a75ac31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_good.sum() > 0:\n",
    "    # Convert into a dataframe\n",
    "    good_df = ijk_groups.first().loc[good_ijks]\n",
    "    good_df['duration'] = ijk_groups['duration'].mean().loc[good_ijks]\n",
    "    good_df = good_df.sort_values('duration')\n",
    "    best_row = good_df.iloc[0]\n",
    "\n",
    "    # Print the best (quickest while still valid) combination\n",
    "    print(\n",
    "        feature_detectors[best_row['i_fd']],\n",
    "        feature_matchers[best_row['j_fm']],\n",
    "        transform_kwargs[best_row['k_tk']]\n",
    "    )\n",
    "else:\n",
    "    print('No single set of parameters works for all images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2a461-a822-4554-b073-ea0c3c864515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a33f4-383d-4a02-af97-1870e7cf8c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff013136-66ae-4b6b-8178-1eb995c1bb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
