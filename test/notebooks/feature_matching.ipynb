{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01757494-59c0-4d23-9e86-c573f1456686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature Matching\n",
    "\n",
    "This notebook evaluates feature matching performance for a number of test scenarios.\n",
    "\n",
    "TODO: There are images that clearly have bad homographies, but are added together nevertheless.\n",
    "\n",
    "TODO: Refactor the code in here to use the code that the mosaics use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c49e2-2d49-4b74-9c17-1db353507044",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51949404-7b33-4e69-8cb5-acb7823ed70d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2439067-da17-46ea-b352-7c486a6e2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c22acd-8dff-4b33-a519-0b1bafd4c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.utils import check_random_state\n",
    "import tqdm.notebook\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba2ddf-e6da-4b90-8258-0285e13db00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ac252-2f92-4b51-9b68-835fcc917263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from night_horizons import utils, raster, features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51309b6c-5a10-412c-8185-3a4401d46c65",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb7f2-ef43-4560-bf23-b5f21e68db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yml', \"r\", encoding='UTF-8') as file:\n",
    "    settings = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca608e00-e559-4047-83ed-f90c6be339fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_settings = {\n",
    "    # Filetree settings\n",
    "    'test_images_dir': '../test_data/feature_matching/',\n",
    "    'src_format': 'src_{:03d}.tiff',\n",
    "    'dst_format': 'dst_{:03d}.tiff',\n",
    "\n",
    "    # Feature matching options\n",
    "    'feature_detectors': [\n",
    "        ('ORB', {}),\n",
    "        ('SIFT', {}),\n",
    "        # Still marked as patented in the opencv version I'm using.\n",
    "        # (cv2.xfeatures2d.SURF_create, {}),\n",
    "        ('AKAZE', {}),\n",
    "        # ('BRISK', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('FastFeatureDetector', {}),\n",
    "        # Does not seem to be fully implemented in OpenCV\n",
    "        # ('MSER', {}),\n",
    "    ],\n",
    "    'feature_matchers': [\n",
    "        # TODO: Explore other feature matchers.\n",
    "        ('BFMatcher', {}),\n",
    "        # ('FlannBasedMatcher', {}),\n",
    "        # ('BFMatcher', {'k': [10,]}),\n",
    "        # TODO: Try Grid-based Motion Statistics. Very fast, but more complicated.\n",
    "    ],\n",
    "    'transform_param_grid': {\n",
    "        'homography_method': [\n",
    "            cv2.RANSAC,\n",
    "            # cv2.RHO,\n",
    "            # These don't really show promise\n",
    "            # cv2.LMEDS,\n",
    "            # 0,\n",
    "        ],\n",
    "        # 'ransacReprojThreshold': np.arange(1, 10),\n",
    "        # 'maxIters': [100, 1000, 2000, 10000],\n",
    "        'n_matches_used': [10, 100, 500, None],\n",
    "        'dark_frame_brightness': [0.03, ],\n",
    "        'dark_frame_percentile': [0.99, ],\n",
    "    },\n",
    "\n",
    "    # Analysis parameters\n",
    "    'det_min': 0.6,\n",
    "    'det_max': 2.,\n",
    "    'n_images': 10000,\n",
    "    'show_images': True,\n",
    "}\n",
    "settings.update(local_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bfdfb-b036-45cb-ab2b-3a40f7669c1d",
   "metadata": {},
   "source": [
    "## Parse Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cacdff-8d09-4fda-9c71-33423e87ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature detectors\n",
    "feature_detectors = []\n",
    "for subsettings in settings['feature_detectors']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_detectors.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_detectors += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507e051-85b3-4460-8267-ebfa8d842769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature matchers\n",
    "feature_matchers = []\n",
    "for subsettings in settings['feature_matchers']:\n",
    "\n",
    "    if len(subsettings[1]) == 0:\n",
    "        feature_matchers.append(subsettings)\n",
    "        continue\n",
    "    \n",
    "    # Generate all permutations of values\n",
    "    param_grid = subsettings[1]\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    permutations = itertools.product(*values)\n",
    "    \n",
    "    list_addition = [\n",
    "        (\n",
    "            subsettings[0],\n",
    "            dict(zip(keys, permutation))\n",
    "        )\n",
    "        for permutation in permutations\n",
    "    ]\n",
    "    feature_matchers += list_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb013f15-4a00-43de-9c44-4c409d689319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transform kwargs\n",
    "\n",
    "# Generate all permutations of values\n",
    "param_grid = settings['transform_param_grid']\n",
    "keys, values = zip(*param_grid.items())\n",
    "permutations = itertools.product(*values)\n",
    "\n",
    "transform_kwargs = [\n",
    "    dict(zip(keys, permutation))\n",
    "    for permutation in permutations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74e095-69d5-4d1c-8f65-704e7fe3eda1",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c71755-ab15-46ea-83e3-f0d5e32dec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinSearcher:\n",
    "\n",
    "    def __init__(self, src_fp, dst_fp):\n",
    "\n",
    "        self.src_fp = src_fp\n",
    "        self.src_image = raster.Image.open(src_fp)\n",
    "        self.src_img = self.src_image.img_int\n",
    "        self.dst_fp = dst_fp\n",
    "        self.dst_image = raster.Image.open(dst_fp)\n",
    "        self.dst_img = self.dst_image.img_int\n",
    "\n",
    "    def show_before(self, img='semitransparent_img'):\n",
    "\n",
    "        subplot_mosaic = [['dst_img', 'src_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['dst_img']\n",
    "        self.dst_image.show(ax=ax, img=img)\n",
    "        ax.set_title('dst')\n",
    "        \n",
    "        ax = ax_dict['src_img']\n",
    "        self.src_image.show(ax=ax, img=img)\n",
    "        ax.set_title('src')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def show_after(self, img='semitransparent_img'):\n",
    "        \n",
    "        # View results\n",
    "        subplot_mosaic = [['warped_img', 'blended_img']]\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        ax_dict = fig.subplot_mosaic(subplot_mosaic)\n",
    "        \n",
    "        ax = ax_dict['warped_img']\n",
    "        self.warped_image.show(ax=ax, img=img)\n",
    "        ax.set_title('warped')\n",
    "        \n",
    "        ax = ax_dict['blended_img']\n",
    "        self.blended_image.show(ax=ax, img=img)\n",
    "        ax.set_title('blended')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    def warp_and_blend(self, M):\n",
    "        \n",
    "        # Warp image\n",
    "        self.warped_img = features.ImageJoiner.warp(self.src_img, self.dst_img, M)\n",
    "        self.warped_image = raster.Image(self.warped_img)\n",
    "\n",
    "        # Blend images\n",
    "        self.blended_img = features.ImageJoiner.blend(self.warped_img, self.dst_img)\n",
    "        self.blended_image = raster.Image(self.blended_img)\n",
    "\n",
    "    def grid_search(self, feature_detectors, feature_matchers, transform_kwargs, log_keys=['abs_det_M', 'dark_frac']):\n",
    "\n",
    " \n",
    "        n_fd = len(feature_detectors)\n",
    "        n_fm = len(feature_matchers)\n",
    "        n_t = len(transform_kwargs)\n",
    "        n_tot = n_fd * n_fm * n_t\n",
    "\n",
    "\n",
    "        rows = []\n",
    "        # TODO: Somehow the number of iterations doesn't match with pbar\n",
    "        with tqdm.notebook.tqdm(total=n_tot) as pbar:\n",
    "            for i, fd_settings in enumerate(feature_detectors):\n",
    "                pbar.update(1)\n",
    "                \n",
    "                for j, fm_settings in enumerate(feature_matchers):\n",
    "                    pbar.update(1)\n",
    "    \n",
    "                    for k, t_kwargs in enumerate(transform_kwargs):\n",
    "    \n",
    "                        image_joiner = features.ImageJoiner(\n",
    "                            feature_detector=fd_settings[0],\n",
    "                            feature_detector_options=fd_settings[1],\n",
    "                            feature_matcher=fm_settings[0],\n",
    "                            feature_matcher_options=fm_settings[1],\n",
    "                            log_keys=log_keys,\n",
    "                            debug_mode=True,\n",
    "                            **t_kwargs\n",
    "                        )\n",
    "    \n",
    "                        return_code, results_ijk, log = image_joiner.join(self.src_img, self.dst_img)\n",
    "    \n",
    "                        # Store results\n",
    "                        row = {\n",
    "                            'return_code': return_code,\n",
    "                            'i_fd': i,\n",
    "                            'j_fm': j,\n",
    "                            'k_tk': k,\n",
    "                        }\n",
    "                        # Make blanks for things we want to log no matter what\n",
    "                        row_defaults = {key: np.nan for key in log_keys}\n",
    "                        row.update(row_defaults)\n",
    "                        # Actual update\n",
    "                        row.update(results_ijk)\n",
    "                        row.update(log)\n",
    "                        rows.append(row)\n",
    "\n",
    "                        pbar.update(1)\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Measure of how warped the image is\n",
    "        df['warp_factor'] = np.abs(np.log10(np.abs(df['abs_det_M'])))\n",
    "\n",
    "        # Identify the best set of parameters\n",
    "        df['valid_M'] = df['return_code'] == 'success'\n",
    "        valid_df = df.loc[df['valid_M']]\n",
    "        if len(valid_df) > 0:\n",
    "            best_ind = valid_df.index[valid_df['duration'].argmin()]\n",
    "        else:\n",
    "            best_ind = df.index[df['warp_factor'].argmin()]\n",
    "        best_row = df.loc[best_ind]\n",
    "        t_best_ind = pd.Timedelta(settings['n_images'] * best_row['duration'], unit='second')\n",
    "\n",
    "        # Results\n",
    "        gs_info = {\n",
    "            'n_valid': len(valid_df),\n",
    "            'best_ind': best_ind,\n",
    "            't_best_ind': t_best_ind,\n",
    "            'best_fd': feature_detectors[best_row['i_fd']],\n",
    "            'best_fm': feature_matchers[best_row['j_fm']],\n",
    "            'best_tk': transform_kwargs[best_row['k_tk']],\n",
    "        }\n",
    "\n",
    "        if len(valid_df) > 0:\n",
    "            print(\n",
    "                f'''Grid search complete.\n",
    "                    {gs_info['n_valid']} valid results.\n",
    "                    Best valid time was {best_row['duration']:.2g} seconds, for an estimated total time of {gs_info['t_best_ind']}.\n",
    "                    The best feature detector was {gs_info['best_fd']}\n",
    "                    The best feature matcher was {gs_info['best_fm']}\n",
    "                    The best transform kwargs were {gs_info['best_tk']}\n",
    "                '''\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f'''No successes found. Closest det_min was {best_row['abs_det_M']:.3g}\n",
    "                '''\n",
    "            )\n",
    "\n",
    "        self.df = df\n",
    "        self.best_row = best_row\n",
    "        self.gs_info = gs_info\n",
    "\n",
    "        return df, best_row, gs_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe75c4-d7a5-48d7-95af-d189ae222c11",
   "metadata": {},
   "source": [
    "# Image Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d8d70-8077-4319-acab-87b90ea527ca",
   "metadata": {},
   "source": [
    "## A Particular Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ce8a8-0e77-42a9-97f1-7d5ddd9f7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "src_fp = os.path.join(settings['test_images_dir'], settings['src_format'].format(i))\n",
    "dst_fp = os.path.join(settings['test_images_dir'], settings['dst_format'].format(i))\n",
    "js = JoinSearcher(src_fp, dst_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0c94f-d7f7-40fc-be17-d75d20e11ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if settings['show_images']:\n",
    "    js.show_before(img='img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7debc-b3cc-4eef-a598-3a212c62fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, best_row, grid_search_results = js.grid_search(feature_detectors, feature_matchers, transform_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3b8a9-6a8e-414a-8c56-d319342cf2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'M' in best_row:\n",
    "    js.warp_and_blend(best_row['M'])\n",
    "\n",
    "    if settings['show_images']:\n",
    "        js.show_after()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca74c64-1cea-4c6a-b6b3-449c4f0c21fb",
   "metadata": {},
   "source": [
    "## All Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22722122-dab8-4827-8d23-bf0861f679a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fps = sorted(glob.glob(os.path.join(settings['test_images_dir'], 'src_*.tiff')))\n",
    "dst_fps = sorted(glob.glob(os.path.join(settings['test_images_dir'], 'dst_*.tiff')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351e008-10fd-475f-8366-1b6c4ebb0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, src_fp in enumerate(src_fps):\n",
    "    print(f'i = {i} / {len(src_fps)}')\n",
    "    \n",
    "    dst_fp = dst_fps[i]\n",
    "\n",
    "    fc = JoinSearcher(src_fp, dst_fp)\n",
    "    \n",
    "    df, best_row, grid_search_results = fc.grid_search(feature_detectors, feature_matchers, transform_kwargs)\n",
    "    \n",
    "    df['set'] = i\n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be81117-1ea5-4e29-952f-998b63218630",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaea261-169b-4b33-a75f-788a57a00ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c53f25-2595-471e-a4ec-ed0d0b5aba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ijk'] = 'i' + df['i_fd'].astype(str) + '_j' + df['j_fm'].astype(str) + '_k' + df['k_tk'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0a9b5-ac11-485e-8e44-55786f36066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df.loc[df['valid_M']]\n",
    "valid_or_dark_df = df.loc[df['return_code'].isin(['success', 'dark_frame'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5129c7a-7e58-4bf5-88d0-9363482d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sets = pd.unique(df['set']).size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266b152-e0a9-4979-9dfa-14e91ee87d1d",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c788e2-dac1-4e1a-85b9-f127c4d5a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='duration',\n",
    "    y='warp_factor',\n",
    "    hue='valid_M',\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.axhline(np.abs(np.log10(settings['det_min'])))\n",
    "ax.set_ylim(0, ax.get_ylim()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb01bc-d90b-41c8-9095-de66aa3f898e",
   "metadata": {},
   "source": [
    "### Identify Promising Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cf218-22f5-41df-bb3b-4b7ad87f5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature detectors that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('i_fd')['set'].nunique()\n",
    "promising_fd = [feature_detectors[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "promising_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749e1b8-b83d-448f-a553-daf9402634a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matchers that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('j_fm')['set'].nunique()\n",
    "promising_fm = [feature_matchers[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "promising_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a0285-9c8b-49fc-8e00-506b797a0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform parameters that work across all image pairs\n",
    "n_valid_sets = valid_or_dark_df.groupby('k_tk')['set'].nunique()\n",
    "promising_t_kwargs = [transform_kwargs[_] for _ in n_valid_sets.index[n_valid_sets==n_sets]]\n",
    "method_map = {\n",
    "    getattr(cv2, method): method\n",
    "    for method in ['RANSAC', 'LMEDS', 'RHO']\n",
    "}\n",
    "promising_t_kwargs = [\n",
    "    {\n",
    "        key:(method_map[value] if key == 'method' else value)\n",
    "        for key, value in t_kwargs.items()\n",
    "    } for t_kwargs in promising_t_kwargs\n",
    "]\n",
    "promising_t_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6228cd-8c73-474e-9505-9b121f544984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now the combinations that are fully good\n",
    "ijk_groups = valid_or_dark_df.groupby('ijk')\n",
    "n_valid_sets = ijk_groups['set'].nunique()\n",
    "is_good = n_valid_sets == n_sets\n",
    "good_ijks = n_valid_sets.index[is_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ab78e-431a-4c1d-bb56-e4c2a75ac31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_good.sum() > 0:\n",
    "    # Convert into a dataframe\n",
    "    good_df = ijk_groups.first().loc[good_ijks]\n",
    "    good_df['duration'] = ijk_groups['duration'].mean().loc[good_ijks]\n",
    "    good_df = good_df.sort_values('duration')\n",
    "    best_row = good_df.iloc[0]\n",
    "\n",
    "    # Print the best (quickest while still valid) combination\n",
    "    print(\n",
    "        feature_detectors[best_row['i_fd']],\n",
    "        feature_matchers[best_row['j_fm']],\n",
    "        transform_kwargs[best_row['k_tk']]\n",
    "    )\n",
    "else:\n",
    "    print('No single set of parameters works for all images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2a461-a822-4554-b073-ea0c3c864515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a33f4-383d-4a02-af97-1870e7cf8c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff013136-66ae-4b6b-8178-1eb995c1bb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
