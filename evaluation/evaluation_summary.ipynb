{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "If using perfect approximate georeferencing (exactgeo),\n",
    "everything works perfectly,\n",
    "even for large paddings (up to 2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following settings we can get some pretty good results.\n",
    "\n",
    "- Only referenced images.\n",
    "- Exact georeferencing with small padding.\n",
    "\n",
    "The following variations on training sample.\n",
    "\n",
    "- Near perfect: 10 training samples per camera.\n",
    "- Very good: 10 training samples for the nadir camera. 1 training sample per other camera.\n",
    "- Good: 10 training samples for the nadir camera only.\n",
    "- Okay: 5 training samples per camera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following settings we can get some pretty good results.\n",
    "\n",
    "- Only referenced images.\n",
    "- Approximate georeferencing with 0.5 padding.\n",
    "- 10 training samples per camera\n",
    "\n",
    "The following variations on training sample.\n",
    "\n",
    "- 1.0 padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from night_horizons import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yml', \"r\", encoding='UTF-8') as file:\n",
    "    settings = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_settings = {\n",
    "    'expected_count': 15000,\n",
    "}\n",
    "settings.update(local_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Until I reinstall seaborn, this helps things be less annoying...\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover y pred data\n",
    "data = {}\n",
    "y_pred_fps = utils.discover_data(settings['data_dir'], ['csv'], 'y_pred')\n",
    "data['y_pred'] = [pd.read_csv(_, index_col=0) for _ in y_pred_fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the other data\n",
    "for var_name in ['y_train', 'y_test', 'X_train', 'X_test', 'y_pred']:\n",
    "    var_fps = y_pred_fps.str.replace('y_pred', var_name)\n",
    "    data[var_name] = [pd.read_csv(_, index_col=0) for _ in var_fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get settings\n",
    "mosaic_settings_fps = y_pred_fps.str.replace('y_pred.csv', 'settings.yaml')\n",
    "nb_settings_fps = y_pred_fps.str.replace('y_pred.csv', 'nbsettings.yaml')\n",
    "\n",
    "mosaic_settings = []\n",
    "nb_settings = []\n",
    "for i, settings_fp in enumerate(mosaic_settings_fps):\n",
    "    with open(settings_fp, \"r\", encoding='UTF-8') as file:\n",
    "        mosaic_settings_i = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    mosaic_settings.append(mosaic_settings_i)\n",
    "\n",
    "    with open(nb_settings_fps.iloc[i], \"r\", encoding='UTF-8') as file:\n",
    "        nb_settings_i = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    nb_settings.append(nb_settings_i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the logs\n",
    "log_fps = y_pred_fps.str.replace('y_pred.csv', 'log.csv')\n",
    "logs = [pd.read_csv(_, index_col=0) for _ in log_fps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Quantities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_pred_fp': y_pred_fps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant settings\n",
    "ts_cols = [f'cam{j}_train_size' for j in np.arange(3)]\n",
    "for i, nb_settings_i in enumerate(nb_settings):\n",
    "    for j in np.arange(3):\n",
    "        df.loc[i, ts_cols[j]] = nb_settings_i['train_size'][j]\n",
    "\n",
    "    for setting in ['padding_fraction', 'use_approximate_georeferencing']:\n",
    "        df.loc[i, setting] = nb_settings_i[setting]\n",
    "\n",
    "df['train_size'] = df[ts_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return codes\n",
    "for i, log in enumerate(logs):\n",
    "    ret_counts = log['return_code'].value_counts().astype(int)\n",
    "    cols = [_ + '_count' for _ in ret_counts.index]\n",
    "    df.loc[i, cols] = ret_counts.values\n",
    "    df.loc[i, 'count'] = len(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fractions\n",
    "for col in df.columns:\n",
    "    if not '_count' in col:\n",
    "        continue\n",
    "    df[col.replace('count', 'frac')] = df[col] / df['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset\n",
    "for i, y_pred in enumerate(data['y_test']):\n",
    "    df.loc[i, 'offset_mean'] = y_pred['offset'].mean()\n",
    "    df.loc[i, 'offset_low'] = np.nanpercentile(y_pred['offset'], 16.)\n",
    "    df.loc[i, 'offset_high'] = np.nanpercentile(y_pred['offset'], 84.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durations\n",
    "for i, log in enumerate(logs):\n",
    "    df.loc[i, 'avg_join_duration'] = log['duration'].mean()\n",
    "    df.loc[i, 'avg_iter_duration'] = log['iter_duration'].mean()\n",
    "    df.loc[i, 'total_iter_duration'] = log['iter_duration'].sum()\n",
    "df['expected_iter_duration_hr'] = np.round(\n",
    "    df['avg_iter_duration'] * settings['expected_count'] / 3600.,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the overall grid\n",
    "g = sns.PairGrid(\n",
    "    data=df,\n",
    "    x_vars=['train_size', 'padding_fraction'],\n",
    "    y_vars=['success_frac', 'offset_mean', 'offset_low', 'offset_high'],\n",
    "    hue='use_approximate_georeferencing',\n",
    ")\n",
    "g.map(sns.scatterplot)\n",
    "g.add_legend()\n",
    "\n",
    "# Adjust limits\n",
    "# Success fraction limits\n",
    "for ax in g.axes[0]:\n",
    "    ax.set_ylim(0, 1)\n",
    "# Offset limits\n",
    "for ax in g.axes[1]:\n",
    "    ax.set_ylim(0, ax.get_ylim()[1])\n",
    "for ax in g.axes[2]:\n",
    "    ax.set_ylim(0, ax.get_ylim()[1])\n",
    "for ax in g.axes[3]:\n",
    "    ax.set_ylim(0, ax.get_ylim()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "night-horizons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
