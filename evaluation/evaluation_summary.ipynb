{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "If using perfect approximate georeferencing (exactgeo),\n",
    "everything works perfectly,\n",
    "even for large paddings (up to 2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following settings we can get some pretty good results.\n",
    "\n",
    "- Only referenced images.\n",
    "- Exact georeferencing with small padding.\n",
    "\n",
    "The following variations on training sample.\n",
    "\n",
    "- Near perfect: 10 training samples per camera.\n",
    "- Very good: 10 training samples for the nadir camera. 1 training sample per other camera.\n",
    "- Good: 10 training samples for the nadir camera only.\n",
    "- Okay: 5 training samples per camera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following settings we can get some pretty good results.\n",
    "\n",
    "- Only referenced images.\n",
    "- Approximate georeferencing with 0.5 padding.\n",
    "- 10 training samples per camera\n",
    "\n",
    "The following variations on training sample.\n",
    "\n",
    "- 1.0 padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as plt_transforms\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from night_horizons import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yml', \"r\", encoding='UTF-8') as file:\n",
    "    settings = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_settings = {\n",
    "    'expected_count': 15000,\n",
    "}\n",
    "settings.update(local_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Until I reinstall seaborn, this helps things be less annoying...\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover y pred data\n",
    "data = {}\n",
    "y_pred_fps = utils.discover_data(settings['data_dir'], ['csv'], 'y_pred')\n",
    "data['y_pred'] = [pd.read_csv(_, index_col=0) for _ in y_pred_fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the other data\n",
    "for var_name in ['y_train', 'y_test', 'X_train', 'X_test', 'y_pred']:\n",
    "    var_fps = y_pred_fps.str.replace('y_pred', var_name)\n",
    "    data[var_name] = [pd.read_csv(_, index_col=0) for _ in var_fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get settings\n",
    "mosaic_settings_fps = y_pred_fps.str.replace('y_pred.csv', 'settings.yaml')\n",
    "nb_settings_fps = y_pred_fps.str.replace('y_pred.csv', 'nbsettings.yaml')\n",
    "\n",
    "mosaic_settings = []\n",
    "nb_settings = []\n",
    "for i, settings_fp in enumerate(mosaic_settings_fps):\n",
    "    with open(settings_fp, \"r\", encoding='UTF-8') as file:\n",
    "        mosaic_settings_i = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    mosaic_settings.append(mosaic_settings_i)\n",
    "\n",
    "    with open(nb_settings_fps.iloc[i], \"r\", encoding='UTF-8') as file:\n",
    "        nb_settings_i = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    nb_settings.append(nb_settings_i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the logs\n",
    "log_fps = y_pred_fps.str.replace('y_pred.csv', 'log.csv')\n",
    "logs = [pd.read_csv(_, index_col=0) for _ in log_fps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Quantities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_pred_fp': y_pred_fps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save identifier\n",
    "df['filename'] = df['y_pred_fp'].apply(\n",
    "    os.path.basename\n",
    ").str.replace('_y_pred.csv', '.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant settings\n",
    "ts_cols = [f'cam{j}_train_size' for j in np.arange(3)]\n",
    "for i, nb_settings_i in enumerate(nb_settings):\n",
    "    for j in np.arange(3):\n",
    "        df.loc[i, ts_cols[j]] = nb_settings_i['train_size'][j]\n",
    "\n",
    "    for setting in ['padding_fraction', 'use_approximate_georeferencing']:\n",
    "        df.loc[i, setting] = nb_settings_i[setting]\n",
    "\n",
    "df['train_size'] = df[ts_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return codes\n",
    "for i, log in enumerate(logs):\n",
    "    ret_counts = log['return_code'].value_counts().astype(int)\n",
    "    cols = [_ + '_count' for _ in ret_counts.index]\n",
    "    df.loc[i, cols] = ret_counts.values\n",
    "    df.loc[i, 'count'] = len(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fractions\n",
    "for col in df.columns:\n",
    "    if not '_count' in col:\n",
    "        continue\n",
    "    df[col.replace('count', 'frac')] = df[col] / df['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset\n",
    "for i, y_pred in enumerate(data['y_test']):\n",
    "    df.loc[i, 'offset_median'] = y_pred['offset'].median()\n",
    "    df.loc[i, 'offset_low'] = np.nanpercentile(y_pred['offset'], 16.)\n",
    "    df.loc[i, 'offset_high'] = np.nanpercentile(y_pred['offset'], 84.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durations\n",
    "for i, log in enumerate(logs):\n",
    "    df.loc[i, 'avg_join_duration'] = log['duration'].median()\n",
    "    df.loc[i, 'avg_iter_duration'] = log['iter_duration'].median()\n",
    "    df.loc[i, 'total_iter_duration'] = log['iter_duration'].sum()\n",
    "df['expected_iter_duration_hr'] = np.round(\n",
    "    df['avg_iter_duration'] * settings['expected_count'] / 3600.,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars=['train_size', 'padding_fraction']\n",
    "y_vars=[\n",
    "    'success_frac',\n",
    "    'offset_median', 'offset_low', 'offset_high',\n",
    "    'expected_iter_duration_hr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = {\n",
    "    'offset_median': 'log',\n",
    "    'offset_low': 'log',\n",
    "    'offset_high': 'log',\n",
    "}\n",
    "limits = {\n",
    "    'success_frac': (0.9, 1.0),\n",
    "    'offset_median': (1, df['offset_high'].max()),\n",
    "    'offset_low': (1, df['offset_high'].max()),\n",
    "    'offset_high': (1, df['offset_high'].max()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_cuts = {\n",
    "    'success_frac': (0.97, 1.0),\n",
    "    'offset_median': (0., 100.),\n",
    "    'expected_iter_duration_hr': (0., 7.),\n",
    "    'train_size': (0, 40),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the overall grid\n",
    "g = sns.PairGrid(\n",
    "    data=df,\n",
    "    x_vars=x_vars,\n",
    "    y_vars=y_vars,\n",
    "    hue='use_approximate_georeferencing',\n",
    ")\n",
    "g.map(sns.scatterplot)\n",
    "g.add_legend()\n",
    "\n",
    "# Per-axis adjustments\n",
    "for i, axes in enumerate(g.axes):\n",
    "    y_var = y_vars[i]\n",
    "    for j, ax in enumerate(axes):\n",
    "        x_var = x_vars[j]\n",
    "\n",
    "        if y_var in acceptance_cuts:\n",
    "            ax.fill_between(\n",
    "                x=[0, 1],\n",
    "                y1=[acceptance_cuts[y_var][0], ] * 2,\n",
    "                y2=[acceptance_cuts[y_var][1], ] * 2,\n",
    "                transform = plt_transforms.blended_transform_factory(\n",
    "                    ax.transAxes,\n",
    "                    ax.transData,\n",
    "                ),\n",
    "                color='k',\n",
    "                alpha=0.2,\n",
    "            )\n",
    "        if x_var in acceptance_cuts:\n",
    "            ax.fill_betweenx(\n",
    "                x1=[acceptance_cuts[x_var][0], ] * 2,\n",
    "                x2=[acceptance_cuts[x_var][1], ] * 2,\n",
    "                y=[0, 1],\n",
    "                transform = plt_transforms.blended_transform_factory(\n",
    "                    ax.transData,\n",
    "                    ax.transAxes,\n",
    "                ),\n",
    "                color='k',\n",
    "                alpha=0.2,\n",
    "            )\n",
    "        \n",
    "        if y_var in scales:\n",
    "            ax.set_yscale(scales[y_var])\n",
    "        if y_var in limits:\n",
    "            ax.set_ylim(limits[y_var])\n",
    "\n",
    "        if x_var in scales:\n",
    "            ax.set_xscale(scales[x_var])\n",
    "        if x_var in limits:\n",
    "            ax.set_xlim(limits[x_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify parametetr sets that fit the criteria\n",
    "valid = np.ones(df.index.size).astype(bool)\n",
    "for var in acceptance_cuts:\n",
    "    valid = valid & (df[var] >= acceptance_cuts[var][0])\n",
    "    valid = valid & (df[var] <= acceptance_cuts[var][1])\n",
    "valid_df = df.loc[valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "night-horizons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
